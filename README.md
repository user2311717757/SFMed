# SFMed

SFMed is a large-scale medical domain model that has undergone continued pre-training, supervised fine-tuning, and alignment based on Qwen2-7B-Instruct. Its current performance has comprehensively surpassed that of other open-source medical models and is comparable to proprietary models.


The core functions of SFMed include:

- Medical Consultation: It can act as a doctor to answer users' questions about diseases and other health-related issues. This includes single-turn question-and-answer dialogues as well as multi-turn dialogues with follow-up questions.

- Pharmaceutical Consultation: It understands medical terminology, drug names, and other specialized terms, providing precise professional knowledge in the medical field.

## Update Log

[2024/11/01] ğŸš€[Open-source SFMed and 7B model weightsğŸ¤—](https://huggingface.co/) #todo (Once  the  paper  is  accepted,  we  will  release  our  model.)

### Download

[SFMed-7B-Instruct](https://huggingface.co/) #todo

### Inference

Same inference method as [ğŸ¤—Qwen2-7B-Instruct](https://huggingface.co/Qwen/Qwen2-7B-Instruct)

## Training Data

A total of approximately2.7B tokens, including around1.4B tokens of general corpus and about1.3B tokens from the medical domain.

- ä¸­æ–‡åŒ»ç–—æ•°æ®

| æ•°æ®é›†åç§°                    | æ•°æ®é›†ç®€ä»‹                                                                                                                                                               | æ•°æ®é›†æ¡æ•° | æ•°æ®é›†Tokenæ•° |
| ----------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------- | ------------- |
| CMtMedQA                      | åŒ…å« 70,000 æ¡å¤šè½®å¯¹è¯æ•°æ®é›†ï¼Œæ¥æºäºçœŸå®åŒ»æ‚£äº¤æµï¼ŒåŒ…å«äº†å¤§é‡çš„ä¸»åŠ¨é—®è¯¢è¯­å¥                                                                                               | 68023      | 25569575      |
| ChatMed_Consult_Dataset       | æ¥è‡ªäºäº’è”ç½‘ä¸Šçš„åŒ»ç–—é—®è¯Šé—®é¢˜ï¼Œåæ˜ äº†çœŸå®ä¸–ç•Œçš„ä¸åŒç”¨æˆ·/æ‚£è€…çš„åŒ»ç–—é—®è¯Šéœ€æ±‚ã€‚ç›®å‰responseéƒ½æ˜¯ç”±OpenAI GPT-3.5å¼•æ“å›ç­”çš„                                                    | 549326     | 79788168      |
| DISC-Med-SFT                  | åŒ…å«äº†è¶…è¿‡47ä¸‡ä¸ªè¡ç”Ÿäºç°æœ‰çš„åŒ»ç–—æ•°æ®é›†é‡æ–°æ„å»ºå¾—åˆ°çš„æ ·æœ¬ã€‚                                                                                                               | 464898     | 147775556     |
| MedDiag                       | åŒ»æ‚£ä¹‹é—´çš„ä¸­æ–‡å¯¹è¯                                                                                                                                                       | 2725990    | 351973718     |
| PromptCBLUE                   | å¯¹CBLUEåŸºå‡†è¿›è¡ŒäºŒæ¬¡å¼€å‘ï¼Œå°†16ç§ä¸åŒçš„åŒ»ç–—åœºæ™¯NLPä»»åŠ¡å…¨éƒ¨è½¬åŒ–ä¸ºåŸºäºæç¤ºçš„è¯­è¨€ç”Ÿæˆä»»åŠ¡,å½¢æˆé¦–ä¸ªä¸­æ–‡åŒ»ç–—åœºæ™¯çš„LLMè¯„æµ‹åŸºå‡†                                                   | 151500     | 27127160      |
| ShenNong_TCM                  | ä»¥ä¸­åŒ»è¯çŸ¥è¯†å›¾è°±ä¸ºåŸºç¡€,é‡‡ç”¨ä»¥å®ä½“ä¸ºä¸­å¿ƒçš„è‡ªæŒ‡ä»¤æ–¹æ³•ï¼Œè°ƒç”¨ChatGPTå¾—åˆ°11w+çš„å›´ç»•ä¸­åŒ»è¯çš„æŒ‡ä»¤æ•°æ®ï¼›                                                                         | 112565     | 25168926      |
| cMedQA-V2.0                   | ä¸­å›½ç¤¾åŒºåŒ»ç–—é—®ç­”çš„æ•°æ®é›†                                                                                                                                                 | 226266     | 22608102      |
| huatuo_knowledge_graph_qa     | åŸºäºåŒ»å­¦çŸ¥è¯†å›¾è°±æ„å»ºäº†è¿™ä¸ªQAæ•°æ®é›†ï¼Œå…±æœ‰798444æ¡æ•°æ®ï¼Œå…¶ä¸­é—®é¢˜æ˜¯é€šè¿‡æ¨¡æ¿æ„å»ºçš„ï¼Œç­”æ¡ˆæ˜¯çŸ¥è¯†å›¾è°±ä¸­æ¡ç›®çš„å†…å®¹ã€‚                                                             | 798444     | 30869480      |
| huatuo_sft_train_data         | è®­ç»ƒHuatuoGPTçš„éƒ¨åˆ†æ•°æ®                                                                                                                                                  | 226042     | 67348069      |
| huatuo_encyclopedia_qa        | ä»åŒ»å­¦ç™¾ç§‘å…¨ä¹¦å’ŒåŒ»å­¦æ–‡ç« ä¸­æå–åŒ»å­¦QAå¯¹ã€‚åœ¨ä¸­æ–‡ç»´åŸºç™¾ç§‘ä¸Šæ”¶é›†äº†8699ä¸ªç–¾ç—…ç™¾ç§‘å…¨ä¹¦æ¡ç›®å’Œ2736ä¸ªè¯ç‰©ç™¾ç§‘å…¨ä¹¦æ¡ç›®ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä»åƒé—®å¥åº·ç½‘ç«™ä¸ŠæŠ“å–äº†226432ç¯‡é«˜è´¨é‡çš„åŒ»å­¦æ–‡ç« ã€‚ | 362420     | 135298899     |
| webMedQA                      | ä»åœ¨çº¿å¥åº·å’¨è¯¢ç½‘ç«™æ”¶é›†çš„çœŸå®çš„ä¸­æ–‡åŒ»ç–—é—®ç­”çš„æ•°æ®é›†                                                                                                                       | 316110     | 56211345      |
| Chinese-medical-dialogue-data | ä¸­æ–‡åŒ»ç–—é—®ç­”æ•°æ®é›†                                                                                                                                                       | 792099     | 115022641     |
| CMExam                        | æ¥è‡ªä¸­å›½å›½å®¶åŒ»å¸ˆèµ„æ ¼è€ƒè¯•çš„æ•°æ®é›†ã€‚åŒ…æ‹¬60Kä»¥ä¸Šçš„å¤šé¡¹é€‰æ‹©é¢˜                                                                                                                | 68119      | 15019251      |
| CMB-Exam                      | å…¨æ–¹ä½å¤šå±‚æ¬¡æµ‹è¯„æ¨¡å‹åŒ»ç–—çŸ¥è¯†                                                                                                                                             | 280839     | 18724518      |
| questions                     | ä¸€äº›ä¸­æ–‡åŒ»ç–—æ•°æ®                                                                                                                                                         | 48376      | 4376377       |
| æ•™ç§‘ä¹¦                        | ä¸­æ–‡åŒ»å­¦æ•™ç§‘ä¹¦æ•°æ®                                                                                                                                                       | 21471      | 15179698      |
| Crawler                       | ä»å¥½å¤§å¤«ã€ä¸é¦™å›­ç­‰è‡ªè¡Œçˆ¬å–çš„æ•°æ®                                                                                                                                         | 482922     | 68760072      |
| yiigle                        | ä¸­ååŒ»å­¦æœŸåˆŠæ ‡é¢˜ä¸æ‘˜è¦                                                                                                                                                   | 308869     | 104137233     |

- ä¸­æ–‡é€šç”¨æ•°æ®

| æ•°æ®é›†åç§°    | æ•°æ®é›†ç®€ä»‹                                                                           | æ•°æ®é›†æ¡æ•° | æ•°æ®é›†Tokenæ•° |
| ------------- | ------------------------------------------------------------------------------------ | ---------- | ------------- |
| baike2018qa   | ç™¾ç§‘ç±»é—®ç­”ï¼Œå«æœ‰150ä¸‡ä¸ªé¢„å…ˆè¿‡æ»¤è¿‡çš„ã€é«˜è´¨é‡é—®é¢˜å’Œç­”æ¡ˆ                                | 1470142    | 358976186     |
| webtext2019zh | ç¤¾åŒºé—®ç­”ï¼Œå«æœ‰410ä¸‡ä¸ªé¢„å…ˆè¿‡æ»¤è¿‡çš„ã€é«˜è´¨é‡é—®é¢˜å’Œå›å¤ã€‚                                | 4258310    | 763721567     |
| wiki2019zh    | ç»´åŸºç™¾ç§‘ï¼Œå¯ä»¥åšä¸ºé€šç”¨ä¸­æ–‡è¯­æ–™ï¼Œåšé¢„è®­ç»ƒçš„è¯­æ–™æˆ–æ„å»ºè¯å‘é‡ï¼Œä¹Ÿå¯ä»¥ç”¨äºæ„å»ºçŸ¥è¯†é—®ç­”ã€‚ | 1248027    | 314398588     |

## è¯„æµ‹

è¯„æµ‹æ•°æ®é›†ï¼š

è¯„æµ‹æ•°æ®é›†åŒ…æ‹¬å¤šè½®å¯¹è¯ã€å•è½®å¯¹è¯ã€åŒ»å­¦åè¯è§£é‡ŠåŠé€‰æ‹©é¢˜æ•°æ®

- CMtMedQAï¼š[https://github.com/SupritYoung/Zhongjing/blob/main/data/CMtMedQA_test.json](https://github.com/SupritYoung/Zhongjing/blob/main/data/CMtMedQA_test.json)
- huatuo26Mï¼š[https://huggingface.co/datasets/FreedomIntelligence/huatuo26M-testdatasets](https://huggingface.co/datasets/FreedomIntelligence/huatuo26M-testdatasets)
- webMedQAï¼š[https://github.com/hejunqing/webMedQA](https://github.com/hejunqing/webMedQA)
- medtikuï¼š[https://www.medtiku.com/](https://www.medtiku.com/)
- é€‰æ‹©é¢˜ï¼šä»CEvalç­‰æŠ½å–å¾—åˆ°çš„ä¸åŒ»ç–—é¢†åŸŸç›¸å…³çš„é€‰æ‹©é¢˜æ•°æ®

è¯„æµ‹æ–¹å¼ï¼š

ä¸‹è½½è¯„æµ‹æ•°æ®é›†ï¼Œæ›¿æ¢æ¨¡å‹è·¯å¾„åï¼Œè¿è¡Œä¸‹é¢çš„ä»£ç å³å¯ã€‚

ä¾èµ–åº“ï¼š[SWIFT](https://github.com/modelscope/ms-swift)

```python
python infer_vllm.py --model_path æ¨¡å‹è·¯å¾„
```

### 1. ä¸æƒå¨åŒ»ç–—å¼€æºæ¨¡å‹çš„å¯¹æ¯”ç»“æœ

| QA-Rouge     |           | SFMed vs. HuatuoGPT-II      | SFMed vs. Zhongjing            | SFMed vs. ChiMed-GPT           | SFMed vs. WiNGPT2           |
| ------------ | --------- | --------------------------- | ------------------------------ | ------------------------------ | --------------------------- |
| å¤šè½®å¯¹è¯     | CMtMedQA  | **0.7544/0.0/0.2456** | **0.5919/0.0019/0.4062** | **0.8607/0.0019/0.1373** | 0.3675/0.0/0.6325           |
| å•è½®å¯¹è¯     | All       | **0.558/0.008/0.434** | **0.539/0.014/0.447**    | **0.5/0.013/0.487**      | **0.545/0.01/0.445**  |
|              | huatuo26M | **0.584/0.008/0.408** | **0.506/0.016/0.478**    | **0.506/0.008/0.486**    | **0.532/0.008/0.46**  |
|              | webMedQA  | **0.532/0.008/0.46**  | **0.572/0.012/0.416**    | **0.494/0.018/0.488**    | **0.558/0.012/0.43**  |
| åŒ»å­¦åè¯è§£é‡Š | medtiku   | **0.76/0.003/0.237**  | **0.638/0.002/0.36**     | **0.687/0.005/0.308**    | **0.654/0.001/0.345** |

| QA-GPT   |           | SFMed vs. HuatuoGPT-II         | SFMed vs. Zhongjing            | SFMed vs. ChiMed-GPT           | SFMed vs. WiNGPT2              |
| -------- | --------- | ------------------------------ | ------------------------------ | ------------------------------ | ------------------------------ |
| å¤šè½®å¯¹è¯ | CMtMedQA  | **0.3907/0.4874/0.1219** | **0.6209/0.3366/0.0426** | **0.9884/0.0097/0.0019** | **0.6209/0.3133/0.0658** |
| å•è½®å¯¹è¯ | All       | **0.242/0.567/0.186**    | **0.702/0.248/0.045**    | **0.975/0.013/0.005**    | **0.861/0.114/0.019**    |
|          | huatuo26M | **0.282/0.54/0.178**     | **0.712/0.244/0.044**    | **0.972/0.016/0.008**    | **0.876/0.106/0.014**    |
|          | webMedQA  | **0.202/0.594/0.194**    | **0.692/0.252/0.046**    | **0.978/0.01/0.002**     | **0.846/0.122/0.024**    |

| é€‰æ‹©é¢˜ | HuatuoGPT-II | Zhongjing | ChiMed-GPT | WiNGPT2 | SFMed            |
| ------ | ------------ | --------- | ---------- | ------- | ---------------- |
| All    | 0.1844       | 0.1195    | 0.3348     | 0.3075  | **0.7596** |
| PLE    | 0.11         | 0.085     | 0.21       | 0.265   | **0.685**  |
| Ceval  | 0.2683       | 0.1463    | 0.4146     | 0.439   | **0.7073** |
| CMB    | 0.155        | 0.08      | 0.27       | 0.275   | **0.765**  |
| CMMLU  | 0.2084       | 0.1315    | 0.379      | 0.3343  | **0.7902** |
| CMExam | 0.185        | 0.145     | 0.35       | 0.26    | **0.73**   |

### 2. ä¸å…¶ä»–æ¨¡å‹çš„å¯¹æ¯”ç»“æœ

| QA-Rouge     |           | SFMed vs. Qwen2-7B-Instruct    | SFMed vs. ChatGPT           | SFMed vs. GPT-4             |
| ------------ | --------- | ------------------------------ | --------------------------- | --------------------------- |
| å¤šè½®å¯¹è¯     | CMtMedQA  | **0.8124/0.0019/0.1857** | 0.3424/0.0019/0.6557        | **0.6538/0.0/0.3462** |
| å•è½®å¯¹è¯     | All       | **0.71/0.002/0.288**     | 0.451/0.01/0.539            | **0.54/0.007/0.453**  |
|              | huatuo26M | **0.754/0.002/0.244**    | 0.416/0.008/0.576           | **0.55/0.006/0.444**  |
|              | webMedQA  | **0.666/0.002/0.332**    | 0.486/0.012/0.502           | **0.53/0.008/0.462**  |
| åŒ»å­¦åè¯è§£é‡Š | medtiku   | **0.94/0.0/0.06**        | **0.605/0.006/0.389** | **0.842/0.0/0.158**   |

| QA-GPT   |           | SFMed vs. Qwen2-7B-Instruct | SFMed vs. ChatGPT             | SFMed vs. GPT-4      |
| -------- | --------- | --------------------------- | ----------------------------- | -------------------- |
| å¤šè½®å¯¹è¯ | CMtMedQA  | 0.089/0.5841/0.3269         | **0.265/0.5861/0.1489** | 0.1644/0.5184/0.3172 |
| å•è½®å¯¹è¯ | All       | 0.087/0.593/0.316           | **0.325/0.554/0.117**   | 0.037/0.505/0.452    |
|          | huatuo26M | 0.11/0.568/0.322            | **0.364/0.506/0.13**    | 0.056/0.516/0.426    |
|          | webMedQA  | 0.064/0.618/0.31            | **0.286/0.602/0.104**   | 0.018/0.494/0.478    |

| é€‰æ‹©é¢˜ | ChatGPT | gpt-4  | qwen2-7b-instruct | SFMed            |
| ------ | ------- | ------ | ----------------- | ---------------- |
| All    | 0.4875  | 0.7072 | 0.7153            | **0.7596** |
| PLE    | 0.405   | 0.685  | 0.61              | **0.685**  |
| Ceval  | 0.561   | 0.7317 | **0.7561**  | 0.7073           |
| CMB    | 0.49    | 0.68   | 0.72              | **0.765**  |
| CMMLU  | 0.5021  | 0.7287 | 0.7483            | **0.7902** |
| CMExam | 0.5     | 0.675  | 0.69              | **0.73**   |

## å…è´£å£°æ˜ #todo

SFMedä¿¡æ¯å¯èƒ½æœ‰è¯¯ï¼Œèš‚èšå¯†ç®—ç§‘æŠ€ä¸ä¿è¯å…¶å‡†ç¡®æ€§ã€å¯é æ€§ç­‰ï¼Œç”¨æˆ·éœ€è‡ªè¡Œæ‰¿æ‹…ä½¿ç”¨ç»“æœå’Œå†³ç­–è´£ä»»ï¼›èš‚èšå¯†ç®—ç§‘æŠ€ä¸æ‰¿æ‹…å› ç¬¬ä¸‰æ–¹åŸå› é€ æˆçš„æŸå®³è´£ä»»ã€‚SFMedè¾“å‡ºçš„å†…å®¹ä¸ä»£è¡¨èš‚èšå¯†ç®—ç§‘æŠ€çš„ç«‹åœºï¼Œèš‚èšå¯†ç®—ç§‘æŠ€ä¸å¯¹æ¨¡å‹å›ç­”æ‰¿æ‹…è´£ä»»ï¼Œç”¨æˆ·åº”åŸºäºä¸ªäººåˆ¤æ–­ä½¿ç”¨ä¿¡æ¯ï¼Œè‡ªè´ŸåŒ»å­¦é£é™©ã€‚

## è®¸å¯è¯ #todo

1. æœ¬é¡¹ç›®æˆæƒåè®®ä¸º Apache License 2.0ï¼Œæ¨¡å‹æƒé‡éœ€è¦éµå®ˆåŸºç¡€æ¨¡å‹[Qwen2-7B-Instruct](https://github.com/QwenLM/Qwen2)ç›¸å…³åè®®åŠ[è®¸å¯è¯](https://huggingface.co/Qwen/Qwen2-7B-Instruct/blob/main/LICENSE)ï¼Œè¯¦ç»†å†…å®¹å‚ç…§å…¶ç½‘ç«™ã€‚
2. ä½¿ç”¨æœ¬é¡¹ç›®åŒ…æ‹¬æ¨¡å‹æƒé‡æ—¶è¯·å¼•ç”¨æœ¬é¡¹ç›®ï¼šhttps://github.com/

## è‡´è°¢ ğŸŠ #todo

æœ¬é¡¹ç›®ç”±èš‚èšé›†å›¢-èš‚èšå¯†ç®—ç§‘æŠ€å‘èµ·ï¼Œè´Ÿè´£åŒå­¦æœ‰é»„ç‚œã€å¼ å…†ã€ç‹è¹æ¡‚ï¼ŒåŒæ—¶æ„Ÿè°¢æä¾›çš„å®è´µæ•°æ®å’Œç®—åŠ›èµ„æºã€‚

- æ„Ÿè°¢ [hiyouga](https://github.com/hiyouga/LLaMA-Efficient-Tuning) æä¾›çš„å¤§æ¨¡å‹å¾®è°ƒæ¡†æ¶ã€‚
- æ„Ÿè°¢ [SWIFT](https://github.com/modelscope/ms-swift) æä¾›çš„ vllmæ¨ç†åŠ é€Ÿæ¡†æ¶ã€‚
- æœ¬é¡¹ç›®åŸºäº [Qwen2-7B-Instruct](https://huggingface.co/Qwen/Qwen2-7B-Instruct)ã€‚

## å¼•ç”¨ #todo

å¦‚æœæ‚¨ä½¿ç”¨æˆ–æ‰©å±•æˆ‘ä»¬çš„å·¥ä½œï¼Œè¯·ä½¿ç”¨å¦‚ä¸‹çš„å¼•ç”¨æ ¼å¼

```bibtex
@misc{SFMed,
  title = {SFMed},
  author = {},
  howpublished = {\url{https://github.com/}},
  year = {2024}
```

## è”ç³»æˆ‘ä»¬

é‚®ç®±ï¼š

- [yinggui.wyg@antgroup.com](mailto:yinggui.wyg@antgroup.com)
- [hw378176@antgroup.com](mailto:hw378176@antgroup.com)
- [quanjun.zz@antgroup.com](mailto:quanjun.zz@antgroup.com)

